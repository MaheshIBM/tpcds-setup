#!/bin/bash

${WORKDIR?"Need to set WORKDIR env"} 2>/dev/null

${SPARK_HOME?"Need to set SPARK_HOME env"} 2>/dev/null
${HADOOP_HOME?"Need to set HADOOP_HOME env"} 2>/dev/null
# ${SPARK_EVENT_LOG_PATH?"Need to set SPARK_EVENT_LOG_PATH env"} 2>/dev/null
# ${HADOOP_USER_NAME?"Ned to set HADOOP_USER_NAME env"} 2>/dev/null

# SPARK_HOME=${SPARK_HOME:-"/home/joe/spark-1.6.2-ppc64le"}
# HADOOP_HOME=${HADOOP_HOME:-"/usr/iop/4.1.0.0/hadoop"}
SPARK_EVENT_LOG_PATH=${SPARK_EVENT_LOG_PATH:-"/tmp/spark-events"}
HADOOP_USER_NAME=${HADOOP_USER_NAME:-`whoami`}

mkdir -p $SPARK_EVENT_LOG_PATH

export HADOOP_USER_NAME=${HADOOP_USER_NAME}

REPO_DIR=${WORKDIR}/tpcds-setup
DEPSDIR=${REPO_DIR}/tpcdeps

QUERIES_DIR=${REPO_DIR}/tpcds_queries
ARCH=`uname -a | awk '{ print \$12 }'`

SQLPERF_JAR=${DEPSDIR}/spark-sql-perf/target/scala-2.10/spark-sql-perf*.jar
if ! ls ${SQLPERF_JAR} 1> /dev/null 2>&1; then
    echo "spark-sql-perf jar file not found!. Aborting."
    exit 255
fi

JMETER_BIN=${DEPSDIR}/apache-jmeter-2.13/bin/jmeter
if [ ! -f ${JMETER_BIN} ]; then
    echo "Jmeter binary not found!. Aborting."
    exit 255
fi

KIT_PATH=${DEPSDIR}/tpcds-kit/tools
if [ ! -d ${KIT_PATH} ]; then
    echo "TPCDS Kit tools directory not found!. Aborting."
    exit 255
fi

type DN >/dev/null 2>&1 || { echo >&2 "Require DN script to be in path. Aborting."; exit 1; }

for nodes in `cat ${HADOOP_HOME}/etc/hadoop/slaves `; do
	ssh $nodes ls ${KIT_PATH} >/dev/null 2>&1 
	if [ $? -ne 0 ] ; then
		echo "TPCDS Kit tools directory not found in $nodes under ${KIT_PATH}. Aborting."
	    exit 255
	fi
done

LOG_DIR=${WORKDIR}/tpcds_logs/
mkdir -p $LOG_DIR

NMON_DIR=${WORKDIR}/nmon_logs

# Runtime config paramters
DRIVER_MEM=30g
DRIVER_CORES=10
EXEC_MEM_OVERHEAD=1536
SHUFFLE_PARTITIONS=64
NUM_EXECUTORS=27
EXEC_CORES=15
EXEC_MEM=20g
GC_THREADS=9

